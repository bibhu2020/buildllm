{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM4gXP2s/gXl3teKEr5cr8h"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Logistic Regression"],"metadata":{"id":"rzs9J4-kFsU3"}},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1hmkMMr2FhsK","executionInfo":{"status":"ok","timestamp":1762376203098,"user_tz":480,"elapsed":139,"user":{"displayName":"Bibhu Mishra","userId":"12646824449670614646"}},"outputId":"60ea395b-57ef-472e-89dc-bf33f26b80ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["569 30\n","Epoch 001: loss = 0.68908179\n","Epoch 011: loss = 0.54431152\n","Epoch 021: loss = 0.45718622\n","Epoch 031: loss = 0.39971384\n","Epoch 041: loss = 0.35895222\n","Epoch 051: loss = 0.32843864\n","Epoch 061: loss = 0.30463773\n","Epoch 071: loss = 0.28546733\n","Epoch 081: loss = 0.26962674\n","Epoch 091: loss = 0.25626376\n","Training accuracy: 0.9122806787490845\n"]}],"source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","from sklearn import datasets\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import r2_score, mean_absolute_error\n","import matplotlib.pyplot as plt\n","\n","# 0️⃣ Prepare data\n","bc = datasets.load_breast_cancer()\n","X, y = bc.data, bc.target\n","\n","n_samples, n_features = X.shape # returns rows, columns\n","print(n_samples, n_features)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n","\n","# scale the features\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)\n","\n","X_train = torch.from_numpy(X_train.astype(np.float32))\n","y_train = torch.from_numpy(y_train.astype(np.float32))\n","X_test = torch.from_numpy(X_test.astype(np.float32))\n","y_test = torch.from_numpy(y_test.astype(np.float32))\n","\n","# Reshape the data\n","y_train = y_train.view(y_train.shape[0], 1)\n","y_test = y_test.view(y_test.shape[0], 1)\n","\n","n_samples, n_features = X.shape\n","\n","# 1️⃣ Design model\n","input_size = n_features\n","output_size = 1\n","class LogisticRegression(nn.Module):\n","  def __init__(self, input_dim, output_dim):\n","    super(LogisticRegression, self).__init__()\n","    self.linear = nn.Linear(input_dim, output_dim)\n","\n","  def forward(self, x):\n","    y_predicted = self.linear(x)\n","    y_predicted = torch.sigmoid(y_predicted)\n","    return y_predicted\n","\n","model = LogisticRegression(input_size, output_size,)\n","\n","# 2️⃣ Define loss and optimizer\n","criterion = nn.BCELoss() #Binary Cross Entropy Loss\n","learning_rate = 0.01\n","# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","optimizer = torch.optim.ASGD(model.parameters(), lr=learning_rate)\n","\n","# ⚙️ 3️⃣ Training loop\n","epochs = 100\n","for epoch in range(epochs):\n","    # forward pass and loss calculation\n","    y_predicted = model(X_train)\n","    loss = criterion(y_predicted, y_train)\n","\n","    # backward pass\n","    loss.backward()\n","\n","    # update weights\n","    optimizer.step()\n","\n","    # reset gradients\n","    optimizer.zero_grad()\n","\n","    if epoch % 10 == 0:\n","        [w, b] = model.parameters()\n","        print(f\"Epoch {epoch+1:03d}: loss = {loss.item():.8f}\")\n","\n","with torch.no_grad():\n","    y_predicted = model(X_test)\n","    y_predicted_cls = y_predicted.round()\n","    accuracy = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n","    print(f\"Training accuracy: {accuracy}\")\n"]}]}